# Week 2

## Neural Networks Basics
Learn to set up a machine learning problem with a neural network mindset. Learn to use vectorization to speed up your models.

**Learning Objectives**
- Build a logistic regression model, structured as a shallow neural network
- Implement the main steps of an ML algorithm, including making predictions, derivative computation, and gradient descent.
- Implement computationally efficient, highly vectorized, versions of models.
- Understand how to compute derivatives for logistic regression, using a backpropagation mindset.
- Become familiar with Python and Numpy
- Work with iPython Notebooks
- Be able to implement vectorization across multiple training examples

### Logistic Regression as a Neural Network
  - [x] Binary Classification
  - [x] Logistic Regression
  - [x] Logistic Regression Cost Function
  - [x] Gradient Descent
  - [x] Derivatives
  - [x] More Derivative Examples
  - [x] Computation graph
  - [x] Derivatives with a Computation Graph
  - [x] Logistic Regression Gradient Descent
  - [x] Gradient Descent on m Examples

### Python and Vectorization
  - [x] Vectorization
  - [x] More Vectorization Examples
  - [x] Vectorizing Logistic Regression
  - [x] Vectorizing Logistic Regression's Gradient Output
  - [x] Broadcasting in Python
  - [x] A note on python/numpy vectors
  - [x] Quick tour of Jupyter/iPython Notebooks
  - [x] Explanation of logistic regression cost function (optional)

**Quiz**
  - [x] Neural Network Basics
  
**Programming Assignments**
  - [x] Python Basics with numpy
  - [x] Logistic Regression with a Neural Network mindset

## Heroes of Deep Learning
  - [x] LecturePieter Abbeel interview
