# Week 1

## Practical aspects of Deep Learning

**Learning Objectives**
- Recall that different types of initializations lead to different results
- Recognize the importance of initialization in complex neural networks.
- Recognize the difference between train/dev/test sets
- Diagnose the bias and variance issues in your model
- Learn when and how to use regularization methods such as dropout or L2 regularization.
- Understand experimental issues in deep learning such as Vanishing or Exploding gradients and learn how to deal with them
- Use gradient checking to verify the correctness of your backpropagation implementation

### Setting up your Machine Learning Application
- [x] [Train / Dev / Test sets](https://www.youtube.com/watch?v=1waHlpKiNyY&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)
- [x] [Bias / Variance](https://www.youtube.com/watch?v=SjQyLhQIXSM&index=2&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)
- [x] [Basic Recipe for Machine Learning](https://www.youtube.com/watch?v=C1N_PDHuJ6Q&index=3&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)

### Regularizing your neural network
- [x] [Regularization](https://www.youtube.com/watch?v=6g0t3Phly2M&index=4&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)
- [x] [Why regularization reduces overfitting?](https://www.youtube.com/watch?v=NyG-7nRpsW8&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&index=5)
- [x] [Dropout Regularization](https://www.youtube.com/watch?v=D8PJAL-MZv8&index=6&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)
- [x] [Understanding Dropout](https://www.youtube.com/watch?v=ARq74QuavAo&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&index=7)
- [x] [Other regularization methods](https://www.youtube.com/watch?v=BOCLq2gpcGU&index=8&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)

### Setting up your optimization problem
- [x] [Normalizing inputs](https://www.youtube.com/watch?v=FDCfw-YqWTE&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&index=9)
- [x] [Vanishing / Exploding gradients](https://www.youtube.com/watch?v=qhXZsFVxGKo&index=10&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)
- [x] [Weight Initialization for Deep Networks](https://www.youtube.com/watch?v=s2coXdufOzE&index=11&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)
- [x] [Numerical approximation of gradients](https://www.youtube.com/watch?v=y1xoI7mBtOc&index=12&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc)
- [x] [Gradient checking](https://www.youtube.com/watch?v=QrzApibhohY&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&index=13)
- [x] [Gradient Checking Implementation Notes](https://www.youtube.com/watch?v=4Ct3Yujl1dk&list=PLkDaE6sCZn6Hn0vK8co82zjQtt3T2Nkqc&index=14)

**Quiz**
- [x] Practical aspects of deep learning

**Programming assignments**
- [x] Initialization
- [x] Regularization
- [x] Gradient Checking

## Heroes of Deep Learning (Optional)
- [ ] [Yoshua Bengio interview](https://www.youtube.com/watch?v=oJFShOfCZiA&index=4&list=PLkDaE6sCZn6FcbHlDzbVzf3TVgxzxK7lr)
